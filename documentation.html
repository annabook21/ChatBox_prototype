<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS Contextual Chatbot - Final Architecture</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; color: #e0e0e0; background-color: #16191f; margin: 0; padding: 20px; }
        .container { max-width: 1200px; margin: 40px auto; padding: 30px; background-color: #232a35; border-radius: 12px; box-shadow: 0 8px 24px rgba(0,0,0,0.5); }
        h1, h2, h3 { color: #FF9900; border-bottom: 2px solid #3c4a61; padding-bottom: 10px; }
        h1 { font-size: 2.8em; text-align: center; border-bottom: none; }
        h2 { font-size: 2.2em; margin-top: 50px; }
        h3 { font-size: 1.6em; color: #52a7c7; border-bottom: 1px solid #3c4a61; }
        code { background-color: #2c3543; padding: 0.2em 0.5em; border-radius: 5px; font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace; color: #ffca80; }
        pre { background-color: #1a1f26; padding: 15px; border-radius: 8px; overflow-x: auto; border: 1px solid #3c4a61; }
        ul { padding-left: 25px; }
        li { margin-bottom: 0.8em; }
        .mermaid { text-align: center; background-color: #1e242e; border-radius: 12px; padding: 20px; margin: 30px 0; border: 1px solid #3c4a61; }
        .badge { display: inline-block; padding: 5px 12px; border-radius: 16px; font-size: 0.9em; font-weight: 700; margin-left: 10px; vertical-align: middle; }
        .badge-serverless { background-color: #FF9900; color: #232F3E; }
        .badge-rag { background-color: #01A88D; color: white; }
        .badge-secure { background-color: #52a7c7; color: #16191f; }
    </style>
</head>
<body>
    <div class="container">
        <h1>AWS Contextual Chatbot <span class="badge badge-serverless">Serverless</span><span class="badge badge-rag">RAG</span><span class="badge badge-secure">Secure</span></h1>
        <p style="text-align: center; font-size: 1.2em;">A production-ready, retrieval-augmented generation (RAG) solution using Amazon Bedrock Knowledge Bases.</p>

        <h2>Architecture Diagram (Final)</h2>
        <div class="mermaid">
graph TD
    subgraph "User Domain"
        User["ðŸ‘¤ User (Web Browser)"]
    end

    subgraph "AWS Cloud - Global"
        CF["â˜ï¸ CloudFront (CDN)"]
    end

    subgraph "AWS Cloud - Application Region"
        subgraph "API & Frontend Hosting"
            APIGW["ðŸ”Œ API Gateway (REST API)"]
            FrontendS3["ðŸ“¦ S3 (React App + config.json)"]
        end

        subgraph "Application Logic (AWS Lambda)"
            QueryLambda["âš¡ Query Lambda"]
            UploadLambda["âš¡ Upload Lambda"]
            IngestLambda["âš¡ Ingestion Lambda"]
            StatusLambda["âš¡ Status Check Lambda"]
            ModelCheckLambda["âš¡ Pre-Deploy Check"]
        end

        subgraph "Data & AI"
            DocsS3["ðŸ“¦ S3 (Source Documents)"]
            BedrockKB["ðŸ§  Bedrock Knowledge Base"]
            BedrockGuardrail["ðŸ›¡ï¸ Bedrock Guardrail"]
            BedrockModel["ðŸ¤– Bedrock Model (Claude 3)"]
            OSS["ðŸ” OpenSearch Serverless (Vector Store)"]
        end

        subgraph "Observability & Error Handling"
            CloudWatch["ðŸ“Š CloudWatch (Logs, Metrics, Dashboard, Alarms)"]
            XRay["ðŸ”¬ AWS X-Ray (Traces)"]
            SNS["ðŸ”” SNS Topic (Alerts)"]
            SQS_DLQ["ðŸ“¥ SQS DLQ (Failed Ingestions)"]
        end
    end

    %% Data Flows
    User -- "1. HTTPS Request" --> CF
    CF -- "2. Serves React App" --> FrontendS3
    User -- "3. API Calls (/docs, /upload, /status)" --> APIGW

    APIGW -- "4a. POST /upload" --> UploadLambda
    UploadLambda -- "5. Generates Pre-signed URL" --> DocsS3
    User -- "6. Uploads file directly to S3" --> DocsS3

    DocsS3 -- "7. S3 PUT Event" --> IngestLambda
    IngestLambda -- "8. StartIngestionJob" --> BedrockKB
    BedrockKB -- "9. Chunks & Embeds" --> OSS

    APIGW -- "4b. POST /docs" --> QueryLambda
    QueryLambda -- "10. Retrieve()" --> BedrockKB
    BedrockKB -- "11. Semantic Search" --> OSS
    OSS -- "12. Returns Chunks" --> BedrockKB
    BedrockKB -- "13. Returns Context" --> QueryLambda
    QueryLambda -- "14. InvokeModel() with Guardrail" --> BedrockGuardrail
    BedrockGuardrail -- "15. Invokes" --> BedrockModel
    BedrockModel -- "16. Returns Answer" --> BedrockGuardrail
    BedrockGuardrail -- "17. Filtered Answer" --> QueryLambda
    QueryLambda -- "18. Returns Final Response" --> APIGW

    APIGW -- "4c. GET /ingestion-status" --> StatusLambda
    StatusLambda -- "ListIngestionJobs" --> BedrockKB

    IngestLambda -- "On Final Failure" --> SQS_DLQ
    CloudWatch -- "Triggers Alarm on DLQ" --> SNS
    QueryLambda -- "Errors" --> CloudWatch
    IngestLambda -- "Errors" --> CloudWatch
    CloudWatch -- "Triggers Alarm on Errors" --> SNS

    %% Style
    style User fill:#FF9900,color:#000
    style CF fill:#8C4FFF,color:#fff
    style APIGW fill:#FF4F8B,color:#fff
    style FrontendS3 fill:#569A31,color:#fff
    style DocsS3 fill:#569A31,color:#fff
    style QueryLambda,UploadLambda,IngestLambda,StatusLambda,ModelCheckLambda fill:#FF9900,color:#000
    style BedrockKB,BedrockGuardrail,BedrockModel fill:#01A88D,color:#fff
    style OSS fill:#146EB4,color:#fff
    style CloudWatch,XRay,SNS,SQS_DLQ fill:#52a7c7,color:#000
</div>

        <h2>Core Components (Final)</h2>
        <h3>1. Frontend Layer</h3>
        <ul>
            <li><strong>React Application:</strong> Modern, responsive UI with a drag-and-drop file uploader, real-time ingestion status polling, and a clean chat interface.</li>
            <li><strong>CloudFront & S3:</strong> The React app is hosted in a private S3 bucket and served globally by CloudFront, which enforces HTTPS and provides low-latency access via its CDN. Access is restricted using Origin Access Control (OAC).</li>
        </ul>

        <h3>2. API Layer</h3>
        <ul>
            <li><strong>API Gateway:</strong> A fully managed REST API serves as the single entry point for the frontend. It includes CORS configuration and throttling to protect the backend from abuse.
                <ul>
                    <li><code>POST /docs</code>: The main endpoint for asking questions.</li>
                    <li><code>POST /upload</code>: Generates a secure, pre-signed URL for file uploads.</li>
                    <li><code>GET /ingestion-status</code>: Allows the frontend to poll for the status of document processing.</li>
                </ul>
            </li>
        </ul>

        <h3>3. Compute & Application Logic (AWS Lambda)</h3>
        <ul>
            <li><strong>Query Lambda:</strong> Orchestrates the two-step RAG process. It first calls Bedrock's `Retrieve` API, then calls `InvokeModel` with the retrieved context, applying the Guardrail in the process.</li>
            <li><strong>Upload Lambda:</strong> Generates secure, short-lived S3 pre-signed URLs, allowing the frontend to upload large files directly and securely to S3 without passing them through the Lambda.</li>
            <li><strong>Ingestion Lambda:</strong> Automatically triggered by file uploads to the S3 bucket. It starts the Bedrock Knowledge Base ingestion job. It includes a Dead Letter Queue (DLQ) and a 2-retry policy for resilience.</li>
            <li><strong>Status Lambda:</strong> Provides real-time status of the latest ingestion job.</li>
            <li><strong>Pre-Deploy Check Lambda:</strong> A custom resource that runs during `cdk deploy` to ensure the required Bedrock models are enabled, preventing runtime errors.</li>
        </ul>

        <h3>4. AI, Data & Storage</h3>
        <ul>
            <li><strong>S3 Document Bucket:</strong> A secure, encrypted, and versioned S3 bucket that stores all the source documents uploaded by users.</li>
            <li><strong>Amazon Bedrock Knowledge Base:</strong> The core of the RAG engine. It automatically connects to the S3 data source, uses the **Titan G1 Embeddings** model to create vector embeddings, and stores them in a managed **OpenSearch Serverless** collection.</li>
            <li><strong>Amazon Bedrock Model:</strong> The application is hardcoded to use **Anthropic Claude 3 Sonnet** for generating high-quality, contextual answers.</li>
            <li><strong>Amazon Bedrock Guardrails:</strong> Provides a critical layer of Responsible AI by filtering both user prompts and model responses for harmful content across four categories (Hate, Insults, Sexual, Violence).</li>
        </ul>

        <h2>Deployment Guide</h2>
        <p>This guide provides step-by-step instructions to deploy the application using the AWS CDK.</p>
        <h3>Prerequisites</h3>
        <ul>
            <li>AWS Account with administrator-level access.</li>
            <li>AWS CLI installed and configured.</li>
            <li>Node.js (version 20.x or later).</li>
            <li>AWS CDK CLI (`npm install -g aws-cdk`).</li>
            <li>Docker Desktop (must be running).</li>
        </ul>
        <h3>Deployment Steps</h3>
        <ol>
            <li><strong>Clone the Repository</strong> and navigate into the backend directory.</li>
            <li><strong>Enable Bedrock Models:</strong> Follow the critical pre-deployment step at the top of the README to enable Titan Embeddings and Claude 3 Sonnet.</li>
            <li><strong>Install Dependencies:</strong> Run <code>npm install</code> in the `backend` directory.</li>
            <li><strong>Bootstrap CDK (First Time):</strong> Run <code>cdk bootstrap</code> if you've never used CDK in the account/region.</li>
            <li><strong>Deploy:</strong> Run <code>cdk deploy</code>. The process takes 10-15 minutes.</li>
        </ol>

        <h2>Usage Guide</h2>
        <ol>
            <li><strong>Access the Application:</strong> Open the `CloudFrontURL` from the CDK deployment outputs.</li>
            <li><strong>Upload Documents:</strong> Drag and drop your files (PDF, DOCX, etc.) into the upload area.</li>
            <li><strong>Monitor Ingestion:</strong> Wait for the status message to change to `âœ… Ingestion complete!`.</li>
            <li><strong>Ask a Question:</strong> Type a question related to your documents and get a contextual, AI-generated answer with a source citation.</li>
        </ol>

        <h2>Security Considerations</h2>
        <p>Built according to the AWS Well-Architected Framework's Security Pillar.</p>
        <ul>
            <li><strong>IAM Least Privilege:</strong> All roles are scoped with the minimum necessary permissions. `bedrock:InvokeModel` is restricted to the specific Claude 3 Sonnet model ARN.</li>
            <li><strong>Infrastructure Protection:</strong> The S3 bucket blocks all public access and is only accessible via a CloudFront OAC. All data is encrypted at rest.</li>
            <li><strong>Responsible AI:</strong> Bedrock Guardrails filter inputs and outputs for harmful content.</li>
            <li><strong>Data Protection:</strong> The S3 bucket is versioned to protect against accidental deletions.</li>
        </ul>

        <h2>Performance Tuning</h2>
        <ul>
            <li><strong>Lambda Memory:</strong> Analyze "Max Memory Used" in CloudWatch Logs and adjust the `memorySize` in `backend-stack.ts` to improve performance.</li>
            <li><strong>Knowledge Base Chunking:</strong> Adjust the `maxTokens` in the chunking strategy in `backend-stack.ts` if answers are fragmented.</li>
            <li><strong>API Throttling:</strong> Adjust the `rateLimit` and `burstLimit` in the API Gateway Usage Plan to match expected load.</li>
        </ul>

        <h2>Cost Estimation</h2>
        <p>Costs are minimal and often fall within the AWS Free Tier for low traffic. The primary cost driver is Amazon Bedrock usage (pay-per-token). For a scenario with 100 documents and 500 queries per month, the estimated cost is likely **under $5/month**. Use the [AWS Pricing Calculator](https://calculator.aws/) for a detailed estimate.</p>

        <h2>Troubleshooting Guide</h2>
        <ul>
            <li><strong>Deployment Fails on `Bedrock model access denied...`</strong>: You did not enable the required models. See the pre-deployment step.</li>
            <li><strong>`DELETE_FAILED` on `BucketNotificationsHandler`</strong>: Your CloudFormation stack is in a broken state from a previous failed deployment. You must run `cdk destroy` before running `cdk deploy` again.</li>
            <li><strong>"Server side error" at runtime</strong>: Check the `query-bedrock-llm` Lambda logs in CloudWatch. The most common cause is that model access was revoked after deployment.</li>
        </ul>

        <h2>Alternatives Considered</h2>
        <ul>
            <li><strong>`RetrieveAndGenerate` API vs. Manual "Retrieve then Invoke":</strong> We chose the manual two-step process because `RetrieveAndGenerate` does not support Bedrock Guardrails. This was a critical trade-off for implementing Responsible AI features.</li>
            <li><strong>Vector Store:</strong> We used the Bedrock-managed OpenSearch Serverless collection for its zero-management overhead and tight integration.</li>
        </ul>

        <h2>Cleanup</h2>
        <p>To remove all resources and stop incurring charges, run the following command in the `backend` directory:</p>
        <pre><code>cdk destroy</code></pre>

    </div>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({ startOnLoad: true, theme: 'dark' });</script>
</body>
</html>